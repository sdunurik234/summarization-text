# -*- coding: utf-8 -*-
"""Копия блокнота "Добро пожаловать в Colaboratory!"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qre4blNcX6k2nLnqIhDn8uCwWZl7gDu0
"""

pip install datasets

pip install transformers[sentencepiece]

from datasets import load_dataset
data = load_dataset("billsum")
data

from transformers import AutoTokenizer

kerek = "t5-small"
tokenizer = AutoTokenizer.from_pretrained(kerek)
tokenizer

prefix = "summarize: "


def preprocess(examples):
    inputs = [prefix + doc for doc in examples["text"]]
    model_inputs = tokenizer(inputs, max_length=1024, padding="max_length", truncation=True)

    labels = tokenizer(text_target=examples["summary"], padding="max_length", max_length=128, truncation=True)

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

new_data = data.map(preprocess, batched=True)

from transformers import DataCollatorForSeq2Seq, TFAutoModelForSeq2SeqLM

coll = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=kerek, return_tensors="tf")
model = TFAutoModelForSeq2SeqLM.from_pretrained(kerek)

train = model.prepare_tf_dataset(
    new_data["train"],
    shuffle=True,
    batch_size=4,
    collate_fn=coll,
)

test = model.prepare_tf_dataset(
    new_data["test"],
    shuffle=False,
    batch_size=4,
    collate_fn=coll,
)

from transformers import create_optimizer, AdamWeightDecay

optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)

import tensorflow as tf

model.compile(optimizer=optimizer, metrics=["accuracy"])

model.fit(x=train, validation_data=test, epochs=1)

model.save_pretrained("t5-small-sumarization")

tokenizer.save_pretrained("tokenizer")

tokenizer = AutoTokenizer.from_pretrained("/content/tokenizer")

from transformers import pipeline

gen_kwargs = {"length_penalty": 0.8, "num_beams":8, "max_length": 128}

sample_text = new_data["test"][0]["text"]

reference = new_data["test"][0]["summary"]

pipe = pipeline("summarization", model="t5-small-sumarization",tokenizer=tokenizer)

##
print("Dialogue:")
print(sample_text)


print("\nReference Summary:")
print(reference)


print("\nModel Summary:")
print(pipe(sample_text, **gen_kwargs)[0]["summary_text"])

from google.colab import files
files.download('/content/tokenizer/tokenizer_config.json')